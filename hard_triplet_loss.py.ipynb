{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class HardTripletLoss(nn.Module):\n",
    "    \"\"\"Hard/Hardest Triplet Loss\n",
    "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: margin for triplet loss\n",
    "            hardest: If true, loss is considered only hardest triplets.\n",
    "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
    "                If false, output is the pairwise euclidean distance matrix.\n",
    "        \"\"\"\n",
    "        super(HardTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.hardest = hardest\n",
    "        self.squared = squared\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: labels of the batch, of size (batch_size,)\n",
    "            embeddings: tensor of shape (batch_size, embed_dim)\n",
    "\n",
    "        Returns:\n",
    "            triplet_loss: scalar tensor containing the triplet loss\n",
    "        \"\"\"\n",
    "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
    "\n",
    "        if self.hardest:\n",
    "            # Get the hardest positive pairs\n",
    "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
    "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
    "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Get the hardest negative pairs\n",
    "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
    "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
    "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
    "                    1.0 - mask_anchor_negative)\n",
    "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
    "\n",
    "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
    "            triplet_loss = torch.mean(triplet_loss)\n",
    "        else:\n",
    "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
    "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
    "\n",
    "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
    "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "            # and the 2nd (batch_size, 1, batch_size)\n",
    "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
    "\n",
    "            mask = _get_triplet_mask(labels).float()\n",
    "            triplet_loss = loss * mask\n",
    "\n",
    "            # Remove negative losses (i.e. the easy triplets)\n",
    "            triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "            # Count number of hard triplets (where triplet_loss > 0)\n",
    "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
    "            num_hard_triplets = torch.sum(hard_triplets)\n",
    "\n",
    "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
    "\n",
    "        return triplet_loss\n",
    "\n",
    "\n",
    "def _pairwise_distance(x, squared=False, eps=1e-16):\n",
    "    # Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    cor_mat = torch.matmul(x, x.t())\n",
    "    norm_mat = cor_mat.diag()\n",
    "    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
    "    distances = F.relu(distances)\n",
    "\n",
    "    if not squared:\n",
    "        mask = torch.eq(distances, 0.0).float()\n",
    "        distances = distances + mask * eps\n",
    "        distances = torch.sqrt(distances)\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def _get_anchor_positive_triplet_mask(labels):\n",
    "    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "\n",
    "    # Check if labels[i] == labels[j]\n",
    "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "\n",
    "    mask = indices_not_equal * labels_equal\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "\n",
    "    # Check if labels[i] != labels[k]\n",
    "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
    "    mask = labels_equal ^ 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
    "    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
    "    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
    "    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
    "    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1)).to(device)\n",
    "    i_equal_j = torch.unsqueeze(label_equal, 2)\n",
    "    i_equal_k = torch.unsqueeze(label_equal, 1)\n",
    "    valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
    "\n",
    "    mask = distinct_indices * valid_labels   # Combine the two masks\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
